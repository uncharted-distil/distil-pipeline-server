syntax = "proto3";
option go_package = "pipeline";

/*
* This interface is based on the unified API proposal available at
* https://datadrivendiscovery.org/wiki/pages/viewpage.action?pageId=4260430, with changes made to
* account for functionality provided by GRPC. The Core API constitutes a threshold capability,
* aimed at satisfying the train/predict/subset tasks.  We use a URI to point to locations on a file system
* (or other data store), allowing TA3 systems to select a data subset prior to submission to TA2, as well
* as provide a means for TA2 systems to write out the results of pipeline train and predict steps.
*/

import "google/protobuf/descriptor.proto";

extend google.protobuf.FileOptions {
    // 54100 is from the range reserved for internal use within individual organizations.
    // If we will make this protocol public, we should obtain globally unique field number from Google.
    string protocol_version = 54100;
}

// Date-based version string. Use is it to populate version in SessionRequest and SessionResponse messages.
option (protocol_version) = "2017.10.10";

message SessionContext {
    string session_id = 1;
    // ADDITIONAL FUTURE FIELDS
}

enum StatusCode {
    UNKNOWN = 0;
    OK = 1;
    CANCELLED = 2;
    SESSION_UNKNOWN = 3;
    SESSION_ENDED = 4;
    SESSION_EXPIRED = 5;
    INVALID_ARGUMENT = 6;
    RESOURCE_EXHAUSTED = 7;
    UNAVAILABLE = 8;
    FAILED_PRECONDITION = 9;
    OUT_OF_RANGE = 10;
    UNIMPLEMENTED = 11;
    INTERNAL = 12;
    ABORTED = 13;
}

message Status {
    StatusCode code = 1;
    string details = 2; // optional. Ignored if code = OK
}

message Response {
    Status status = 1;
}

// in the future we could also pass arguments allowing one to fork an existing session,
// or provide resource limits on a session (asking TA2 system to terminate work if it exceeds a given limit)
message SessionRequest {
    string user_agent = 1; // some string identifying the name and version of the TA3 system
    string version = 2; // shall be set to protocol_version above
}

message SessionResponse {
    Response response_info = 1;
    string user_agent = 2; // some string identifying the name and version of the TA2 system
    string version = 3; // shall be set to protocol_version above
    SessionContext context = 4;
}

enum Progress {
    SUBMITTED = 0;  // the process was created and needs to run before it is completed
    RUNNING = 1;    // the process is currently running
    UPDATED = 2;    // the process is still running, but intermediate results are available
    COMPLETED = 3;  // process completed and the pipeline/result is now ready for use
    ERRORED = 4;    // the pipeline entered a failed state and shouldn't be used in ExecutePipeline and ExportPipeline (training) or didn't produce results (testing)
}

// enums below are based on values taken from the problem annotation schema defined at
// https://datadrivendiscovery.org/wiki/display/gov/Problem+Annotation+Schema
// as of version 2.12

enum TaskType {                          // Top level classification of the problem
    TASK_TYPE_UNDEFINED = 0;             // TaskType not yet declared
    CLASSIFICATION = 1;
    REGRESSION = 2;
    SIMILARITY_MATCHING = 3;
    LINK_PREDICTION = 4;
    VERTEX_NOMINATION = 5;
    COMMUNITY_DETECTION = 6;
    GRAPH_MATCHING = 7;
    TIMESERIES_FORECASTING = 8;
    COLLABORATIVE_FILTERING = 9;
}

enum TaskSubtype {                       // Secondary classification of the problem
    TASK_SUBTYPE_UNDEFINED = 0;          // TaskSubtype not yet declared
    NONE = 1;                            // No secondary task is applicable for this problem
    BINARY = 2;
    MULTICLASS = 3;
    MULTILABEL = 4;
    UNIVARIATE = 5;
    MULTIVARIATE = 6;
    OVERLAPPING = 7;
    NONOVERLAPPING = 8;
}

enum OutputType {                        // Specifies the type of the output that the model is required to produce
    OUTPUT_TYPE_UNDEFINED = 0;           // Output not yet declared
    CLASS_LABEL = 1;
    PROBABILITY = 2;
    REAL = 3;
    NODE_ID = 4;
    VECTOR_CLASS_LABEL = 5;
    VECTOR_STOCHASTIC = 6;
    VECTOR_REAL = 7;
    FILE = 8;
}

enum Metric {                             // The evaluation metric for any potential solution
    METRIC_UNDEFINED = 0;                 // Metric not yet declared
    ACCURACY = 1;                         // sklearn.metrics.accuracy_score
    F1 = 2;                               // sklearn.metrics.f1_score
    F1_MICRO = 3;                         // sklearn.metrics.f1_score(average='micro')
    F1_MACRO = 4;                         // sklearn.metrics.f1_score(average='macro')
    ROC_AUC = 5;                          // sklearn.metrics.roc_auc_score
    ROC_AUC_MICRO = 6;                    // sklearn.metrics.roc_auc_score(average='micro')
    ROC_AUC_MACRO = 7;                    // sklearn.metrics.roc_auc_score(average='macro')
    ROOT_MEAN_SQUARED_ERROR = 8;          // sqrt(sklearn.metrics.mean_squared_error)
    ROOT_MEAN_SQUARED_ERROR_AVG = 9;      // sum(mean_squared_error_list)/len(mean_squared_error_list)
    MEAN_ABSOLUTE_ERROR = 10;             // sklearn.metrics.mean_absolute_error
    R_SQUARED = 11;                       // sklearn.metrics.r2_score
    NORMALIZED_MUTUAL_INFORMATION = 12;
    JACCARD_SIMILARITY_SCORE = 13;
    EXECUTION_TIME = 14;                  // wall clock time to run the pipeline by TA2
    MEAN_SQUARED_ERROR = 15;              // sklearn.metrics.mean_squared_error
}

message Feature {
    string feature_id = 1; // id of feature within dataset
    string data_uri = 2;   // uri of dataset containing feature
}

message PipelineCreateRequest {
    SessionContext context = 1;
    repeated Feature train_features = 2;  // input path of training corpus
    TaskType task = 3;
    TaskSubtype task_subtype = 4;         // can be set to NONE = 1
    string task_description = 5;          // textual description of the task, if available
    OutputType output = 6;
    repeated Metric metrics = 7;          // specify a list of evaluation metrics
    repeated Feature target_features = 8; // specify a list of targets to predict
    int32 max_pipelines = 9;              // optional maximum number of pipelines to return
                                          // Note that TA2 may still return more pipelines, so TA3 should keep a list
                                          // of the top results sorted by the relevant metric if required
}

message Score {
    Metric metric = 1;
    float value = 2;
}

message Pipeline {
    repeated string predict_result_uris = 1;  // output path to predicted results on training data
    OutputType output = 2;
    repeated Score scores = 3;
}

message PipelineCreateResult {
    Response response_info = 1; // if pipeline_id is empty, this shall be an error, fatal to the whole create process,
                                // and the stream should be closed immediately
                                // if pipeline_id is set and this is an error, it concerns only that single pipeline
                                // (progress_info should be set to ERRORED) and the create process will continue to
                                // create and train the other pipelines
    Progress progress_info = 2; // progress of training this particular pipeline. If ERRORED, TA3 should consider this
                                // pipeline failed and unavailable for ExecutePipeline or ExportPipeline
    string pipeline_id = 3; // required if response_info is not an error
    // Will be set if progress info value is UPDATED or COMPLETED
    Pipeline pipeline_info = 4;
}

message PipelineExecuteRequest {
    SessionContext context = 1;
    string pipeline_id = 2;
    repeated Feature predict_features = 3;  // input feature data to pass to the pipeline
}

message PipelineExecuteResult {
    Response response_info = 1; // status of the overall execution. If an error, stream will be closed immediately
    Progress progress_info = 2;
    string pipeline_id = 3; // always the requested pipeline
    // Will be set if progress info value is UPDATED or COMPLETED
    repeated string result_uris = 4;  // output path to predicted results on eval data
}

message PipelineListRequest {
    SessionContext context = 1;
}

message PipelineDeleteRequest {
    SessionContext context = 1;
    repeated string delete_pipeline_ids = 2; // should not be empty
}

message PipelineListResult {
    Response response_info = 1;
    repeated string pipeline_ids = 2;
}

message PipelineCreateResultsRequest {
    SessionContext context = 1;
    repeated string pipeline_ids = 2; // empty list means all pipelines in the session
}

message PipelineExecuteResultsRequest {
    SessionContext context = 1;
    repeated string pipeline_ids = 2; // empty list means all pipelines in the session
}

message PipelineExportRequest {
    SessionContext context = 1;
    string pipeline_id = 2;
    string pipeline_exec_uri = 3; // uri to the executable file where the requested pipeline is to be persisted
}

message UpdateProblemSchemaRequest {
    message ReplaceProblemSchemaField {
        oneof update {
            TaskType task_type = 1;
            TaskSubtype task_subtype = 2;
            string task_description = 3;
            OutputType output_type = 4;
            Metric metric = 5;
        }
    }
    repeated ReplaceProblemSchemaField updates = 1;
    SessionContext context = 2;
}

service Core {
    // Train step - multiple result messages returned via GRPC streaming.
    rpc CreatePipelines(PipelineCreateRequest) returns (stream PipelineCreateResult) {}

    // Predict step - multiple results messages returned via GRPC streaming.
    rpc ExecutePipeline(PipelineExecuteRequest) returns (stream PipelineExecuteResult) {}

    // Manage pipelines already present in the session.
    rpc ListPipelines(PipelineListRequest) returns (PipelineListResult) {}
    rpc DeletePipelines(PipelineDeleteRequest) returns (PipelineListResult) {}

    // Obtain results; lists existing pipelines then streams new results as they become available
    rpc GetCreatePipelineResults(PipelineCreateResultsRequest) returns (stream PipelineCreateResult) {}
    rpc GetExecutePipelineResults(PipelineExecuteResultsRequest) returns (stream PipelineExecuteResult) {}

    // Export executable of a pipeline, including any optional preprocessing used in session
    rpc ExportPipeline(PipelineExportRequest) returns (Response) {}

    // Update problem schema
    rpc UpdateProblemSchema(UpdateProblemSchemaRequest) returns (Response) {}

    // Session management
    rpc StartSession(SessionRequest) returns (SessionResponse) {}
    rpc EndSession(SessionContext) returns (Response) {}
}
