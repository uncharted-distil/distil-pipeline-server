syntax = "proto3";
package pipeline;

/*
* This interface is based on the unified API proposal available at
* https://datadrivendiscovery.org/wiki/pages/viewpage.action?pageId=4260430, with changes made to
* account for functionality provided by GRPC. The API constitutes a threshold capability,
* aimed at satisfying the train/predict/subset tasks without introducing additional functions to
* support temporary modification of datasets, and their subsequent materialization.  Instead, we use a URI
* to point to locations on HDFS (or other data store), allowing TA3 systems to select a data subset prior to submission to TA2,
* as well as provide a means for TA2 systems to write out the results of pipeline train and predict steps.  This is
* not meant to preclude moving to a scheme whereby TA2 takes more ownership of data, but rather,
* aims to facilitate development of the basic API in the near term.
*/

message SessionContext {
   string session_id = 1;
   // ADDITIONAL FUTURE FIELDS
}

enum StatusCode {
    OK = 0;
    CANCELLED = 1;
    INVALID_ARGUMENT = 2;
    RESOURCE_EXHAUSTED = 3;
    UNAVAILABLE = 4;
    FAILED_PRECONDITION = 5;
    OUT_OF_RANGE = 6;
    UNIMPLEMENTED = 7;
    INTERNAL = 8;
    ABORTED = 9;
    UNKNOWN = 10;
}

message Status {
   StatusCode code = 1;
   string details = 2;
}

message Response {
   SessionContext context = 1;
   Status status = 2;
}

message SessionRequest {} // GRPC requests require an argument - used by StartSession() call

enum Progress {
   SUBMITTED = 0;
   RUNNING = 1;
   COMPLETE = 2;
}

// enums below are based on values taken from the problem annotation schema

enum Task {
   CLASSIFICATION = 0;
   REGRESSION = 1;
}

enum Output {
   CLASS_LABEL = 0;
   PROBABILITY = 1;
   GENERAL_SCORE = 2;
   MULTILABEL = 3;
   REGRESSION_VALUE = 4;
}

enum Metric {
   ACCURACY = 0;
   PRECISION = 1;
   RECALL = 2;

   F1_MICRO = 4;
   F1_MACRO = 5;
   ROC_AUC = 6;
   LOG_LOSS = 7;
   MEAN_SQUARED_ERR = 8;
   ROOT_MEAN_SQUARED_ERR = 9;
   MEAN_ABSOLUTE_ERR = 10;
   MEDIAN_ABSOSLUTE_ERR = 11;
   R2 = 12;
}

message PipelineCreateRequest {
   SessionContext context = 1;
   // could also split into train_dataset_uri, train_targets_uri if training data left unjoined, would
   // make 'target_features' field redundant in that case
   repeated string train_dataset_uris = 2;
   Task task = 3;
   Output output = 4;
   repeated Metric metric = 5;  // specify a list of evaluation metrics
   repeated string target_features = 6;
   int32 max_pipelines = 7;
}

message Score {
    Metric metric = 1;
    float value = 2;
}

message PipelineCreated {
   repeated string predict_result_uris = 1;
   Output output = 2;
   repeated Score score = 3;
}

message PipelineCreateResult {
   Response response_info = 1;
   Progress progress_info = 2;
   string pipeline_id = 3;
   // Will be set if progress info is a value other than COMPLETE
   PipelineCreated pipelineInfo = 4;
}

message PipelineExecuteRequest {
   SessionContext context = 1;
   string pipeline_id = 2;
   repeated string predict_dataset_uris = 3;
}

message PipelineExecuteResult {
   Response response_info = 1;
   Progress progress_info = 2;
   string pipeline_id = 3;
   // Will be set if progress info is a value other than COMPLETE
   repeated string result_uris = 4;
}

service PipelineCompute {
   // Train step - multiple result messages returned via GRPC streaming.
   rpc CreatePipelines(PipelineCreateRequest) returns (stream PipelineCreateResult) {}

   // Predict step - multiple results messages returned via GRPC streaming.
   rpc ExecutePipeline(PipelineExecuteRequest) returns (stream PipelineExecuteResult) {}

   // Session management
   rpc StartSession(SessionRequest) returns (Response) {}
   rpc EndSession(SessionContext) returns (Response) {}
}

